<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 1 The Targeted Learning Roadmap | The tlverse Software Ecosystem for Causal Inference</title>
  <meta name="description" content="An open-source and fully-reproducible electronic set of teaching materials accompanying a full-day short-course on applying the Targeted Learning methodology in practice using the tlverse software ecosystem." />
  <meta name="generator" content="bookdown 0.10.2 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 1 The Targeted Learning Roadmap | The tlverse Software Ecosystem for Causal Inference" />
  <meta property="og:type" content="book" />
  <meta property="og:url" content="https://tlverse.org/acic2019-workshop/" />
  
  <meta property="og:description" content="An open-source and fully-reproducible electronic set of teaching materials accompanying a full-day short-course on applying the Targeted Learning methodology in practice using the tlverse software ecosystem." />
  <meta name="github-repo" content="tlverse/acic2019-workshop" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 1 The Targeted Learning Roadmap | The tlverse Software Ecosystem for Causal Inference" />
  
  <meta name="twitter:description" content="An open-source and fully-reproducible electronic set of teaching materials accompanying a full-day short-course on applying the Targeted Learning methodology in practice using the tlverse software ecosystem." />
  

<meta name="author" content="Mark van der Laan, Alan Hubbard, Jeremy Coyle, Nima Hejazi, Ivana Malenica, Rachael Phillips" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  <link rel="shortcut icon" href="img/logos/favicons/favicon.png" type="image/x-icon" />
<link rel="prev" href="motivation.html">
<link rel="next" href="tlverse.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />







<script src="libs/htmlwidgets-1.3/htmlwidgets.js"></script>
<link href="libs/vis-4.20.1/vis.css" rel="stylesheet" />
<script src="libs/vis-4.20.1/vis.min.js"></script>
<script src="libs/visNetwork-binding-2.0.6/visNetwork.js"></script>
<script src="libs/kePrint-0.0.1/kePrint.js"></script>


<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; position: absolute; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; }
pre.numberSource a.sourceLine:empty
  { position: absolute; }
pre.numberSource a.sourceLine::before
  { content: attr(data-line-number);
    position: absolute; left: -5em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="css/style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">ACIC 2019 tlverse software workshop</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a><ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#important-links"><i class="fa fa-check"></i>Important links</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#about-this-workshop"><i class="fa fa-check"></i>About this workshop</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#outline"><i class="fa fa-check"></i>Outline</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#about-the-instructors"><i class="fa fa-check"></i>About the instructors</a><ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#mark-van-der-laan"><i class="fa fa-check"></i>Mark van der Laan</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#alan-hubbard"><i class="fa fa-check"></i>Alan Hubbard</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#jeremy-coyle"><i class="fa fa-check"></i>Jeremy Coyle</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#nima-hejazi"><i class="fa fa-check"></i>Nima Hejazi</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#ivana-malenica"><i class="fa fa-check"></i>Ivana Malenica</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#rachael-phillips"><i class="fa fa-check"></i>Rachael Phillips</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="motivation.html"><a href="motivation.html"><i class="fa fa-check"></i>Motivation</a></li>
<li class="chapter" data-level="1" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i><b>1</b> The Targeted Learning Roadmap</a><ul>
<li class="chapter" data-level="1.1" data-path="intro.html"><a href="intro.html#the-statistical-model"><i class="fa fa-check"></i><b>1.1</b> The Statistical Model</a></li>
<li class="chapter" data-level="1.2" data-path="intro.html"><a href="intro.html#the-causal-model"><i class="fa fa-check"></i><b>1.2</b> The Causal Model</a></li>
<li class="chapter" data-level="1.3" data-path="intro.html"><a href="intro.html#the-parameter-of-interest"><i class="fa fa-check"></i><b>1.3</b> The Parameter of Interest</a></li>
<li class="chapter" data-level="1.4" data-path="intro.html"><a href="intro.html#identifiability"><i class="fa fa-check"></i><b>1.4</b> Identifiability</a></li>
<li class="chapter" data-level="1.5" data-path="intro.html"><a href="intro.html#estimators-superlearning-and-targeted-maximum-likelihood"><i class="fa fa-check"></i><b>1.5</b> Estimators: SuperLearning and Targeted Maximum Likelihood</a><ul>
<li class="chapter" data-level="1.5.1" data-path="intro.html"><a href="intro.html#superlearning"><i class="fa fa-check"></i><b>1.5.1</b> SuperLearning</a></li>
<li class="chapter" data-level="1.5.2" data-path="intro.html"><a href="intro.html#tmle"><i class="fa fa-check"></i><b>1.5.2</b> TMLE</a></li>
<li class="chapter" data-level="1.5.3" data-path="intro.html"><a href="intro.html#inference"><i class="fa fa-check"></i><b>1.5.3</b> Inference</a></li>
</ul></li>
<li class="chapter" data-level="1.6" data-path="intro.html"><a href="intro.html#the-wash-benefits-example-dataset"><i class="fa fa-check"></i><b>1.6</b> The WASH Benefits Example Dataset</a><ul>
<li class="chapter" data-level="1.6.1" data-path="intro.html"><a href="intro.html#the-variables"><i class="fa fa-check"></i><b>1.6.1</b> The variables</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="tlverse.html"><a href="tlverse.html"><i class="fa fa-check"></i><b>2</b> Welcome to the <code>tlverse</code></a><ul>
<li class="chapter" data-level="2.1" data-path="tlverse.html"><a href="tlverse.html#learning-objectives"><i class="fa fa-check"></i><b>2.1</b> Learning Objectives</a></li>
<li class="chapter" data-level="2.2" data-path="tlverse.html"><a href="tlverse.html#what-is-the-tlverse"><i class="fa fa-check"></i><b>2.2</b> What is the <code>tlverse</code>?</a></li>
<li class="chapter" data-level="2.3" data-path="tlverse.html"><a href="tlverse.html#tlverse-components"><i class="fa fa-check"></i><b>2.3</b> <code>tlverse</code> components</a></li>
<li class="chapter" data-level="2.4" data-path="tlverse.html"><a href="tlverse.html#installation"><i class="fa fa-check"></i><b>2.4</b> Installation</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="ensemble-machine-learning.html"><a href="ensemble-machine-learning.html"><i class="fa fa-check"></i><b>3</b> Ensemble Machine Learning</a><ul>
<li class="chapter" data-level="3.1" data-path="ensemble-machine-learning.html"><a href="ensemble-machine-learning.html#learning-objectives-1"><i class="fa fa-check"></i><b>3.1</b> Learning Objectives</a></li>
<li class="chapter" data-level="3.2" data-path="ensemble-machine-learning.html"><a href="ensemble-machine-learning.html#introduction"><i class="fa fa-check"></i><b>3.2</b> Introduction</a></li>
<li class="chapter" data-level="3.3" data-path="ensemble-machine-learning.html"><a href="ensemble-machine-learning.html#basic-implementation"><i class="fa fa-check"></i><b>3.3</b> Basic Implementation</a><ul>
<li class="chapter" data-level="3.3.1" data-path="ensemble-machine-learning.html"><a href="ensemble-machine-learning.html#wash-benefits-study-example"><i class="fa fa-check"></i><b>3.3.1</b> WASH Benefits Study Example</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="ensemble-machine-learning.html"><a href="ensemble-machine-learning.html#extensions"><i class="fa fa-check"></i><b>3.4</b> Extensions</a><ul>
<li class="chapter" data-level="3.4.1" data-path="ensemble-machine-learning.html"><a href="ensemble-machine-learning.html#customize-learner-hyperparameters"><i class="fa fa-check"></i><b>3.4.1</b> Customize Learner Hyperparameters</a></li>
<li class="chapter" data-level="3.4.2" data-path="ensemble-machine-learning.html"><a href="ensemble-machine-learning.html#screening-covariates"><i class="fa fa-check"></i><b>3.4.2</b> Screening Covariates</a></li>
<li class="chapter" data-level="3.4.3" data-path="ensemble-machine-learning.html"><a href="ensemble-machine-learning.html#cross-validated-super-learner"><i class="fa fa-check"></i><b>3.4.3</b> Cross-validated Super Learner</a></li>
<li class="chapter" data-level="3.4.4" data-path="ensemble-machine-learning.html"><a href="ensemble-machine-learning.html#variable-importance-analysis-with-sl3"><i class="fa fa-check"></i><b>3.4.4</b> Variable Importance Analysis with <code>sl3</code></a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="ensemble-machine-learning.html"><a href="ensemble-machine-learning.html#exercise"><i class="fa fa-check"></i><b>3.5</b> Exercise</a><ul>
<li class="chapter" data-level="3.5.1" data-path="ensemble-machine-learning.html"><a href="ensemble-machine-learning.html#predicting-myocardial-infarction-with-sl3"><i class="fa fa-check"></i><b>3.5.1</b> Predicting Myocardial Infarction with <code>sl3</code></a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="ensemble-machine-learning.html"><a href="ensemble-machine-learning.html#concluding-remarks"><i class="fa fa-check"></i><b>3.6</b> Concluding Remarks</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="the-tmle-framework.html"><a href="the-tmle-framework.html"><i class="fa fa-check"></i><b>4</b> The TMLE Framework</a><ul>
<li class="chapter" data-level="4.1" data-path="the-tmle-framework.html"><a href="the-tmle-framework.html#learning-objectives-2"><i class="fa fa-check"></i><b>4.1</b> Learning Objectives</a></li>
<li class="chapter" data-level="4.2" data-path="the-tmle-framework.html"><a href="the-tmle-framework.html#example-tmle3-for-ate"><i class="fa fa-check"></i><b>4.2</b> Example: <code>tmle3</code> for ATE</a><ul>
<li class="chapter" data-level="4.2.1" data-path="the-tmle-framework.html"><a href="the-tmle-framework.html#load-the-data"><i class="fa fa-check"></i><b>4.2.1</b> Load the Data</a></li>
<li class="chapter" data-level="4.2.2" data-path="the-tmle-framework.html"><a href="the-tmle-framework.html#define-the-variable-roles"><i class="fa fa-check"></i><b>4.2.2</b> Define the variable roles</a></li>
<li class="chapter" data-level="4.2.3" data-path="the-tmle-framework.html"><a href="the-tmle-framework.html#handling-missingness"><i class="fa fa-check"></i><b>4.2.3</b> Handling Missingness</a></li>
<li class="chapter" data-level="4.2.4" data-path="the-tmle-framework.html"><a href="the-tmle-framework.html#create-a-spec-object"><i class="fa fa-check"></i><b>4.2.4</b> Create a “Spec” Object</a></li>
<li class="chapter" data-level="4.2.5" data-path="the-tmle-framework.html"><a href="the-tmle-framework.html#define-the-learners"><i class="fa fa-check"></i><b>4.2.5</b> Define the learners</a></li>
<li class="chapter" data-level="4.2.6" data-path="the-tmle-framework.html"><a href="the-tmle-framework.html#fit-the-tmle"><i class="fa fa-check"></i><b>4.2.6</b> Fit the TMLE</a></li>
<li class="chapter" data-level="4.2.7" data-path="the-tmle-framework.html"><a href="the-tmle-framework.html#evaluate-the-estimates"><i class="fa fa-check"></i><b>4.2.7</b> Evaluate the Estimates</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="the-tmle-framework.html"><a href="the-tmle-framework.html#tmle3-components"><i class="fa fa-check"></i><b>4.3</b> <code>tmle3</code> Components</a><ul>
<li class="chapter" data-level="4.3.1" data-path="the-tmle-framework.html"><a href="the-tmle-framework.html#tmle3_task"><i class="fa fa-check"></i><b>4.3.1</b> <code>tmle3_task</code></a></li>
<li class="chapter" data-level="4.3.2" data-path="the-tmle-framework.html"><a href="the-tmle-framework.html#initial-likelihood"><i class="fa fa-check"></i><b>4.3.2</b> Initial Likelihood</a></li>
<li class="chapter" data-level="4.3.3" data-path="the-tmle-framework.html"><a href="the-tmle-framework.html#targeted-likelihood-updater"><i class="fa fa-check"></i><b>4.3.3</b> Targeted Likelihood (updater)</a></li>
<li class="chapter" data-level="4.3.4" data-path="the-tmle-framework.html"><a href="the-tmle-framework.html#parameter-mapping"><i class="fa fa-check"></i><b>4.3.4</b> Parameter Mapping</a></li>
<li class="chapter" data-level="4.3.5" data-path="the-tmle-framework.html"><a href="the-tmle-framework.html#putting-it-all-together"><i class="fa fa-check"></i><b>4.3.5</b> Putting it all together</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="the-tmle-framework.html"><a href="the-tmle-framework.html#fitting-tmle3-with-multiple-parameters"><i class="fa fa-check"></i><b>4.4</b> Fitting <code>tmle3</code> with multiple parameters</a><ul>
<li class="chapter" data-level="4.4.1" data-path="the-tmle-framework.html"><a href="the-tmle-framework.html#delta-method"><i class="fa fa-check"></i><b>4.4.1</b> Delta Method</a></li>
<li class="chapter" data-level="4.4.2" data-path="the-tmle-framework.html"><a href="the-tmle-framework.html#fit"><i class="fa fa-check"></i><b>4.4.2</b> Fit</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="the-tmle-framework.html"><a href="the-tmle-framework.html#exercise-1"><i class="fa fa-check"></i><b>4.5</b> Exercise</a></li>
<li class="chapter" data-level="4.6" data-path="the-tmle-framework.html"><a href="the-tmle-framework.html#summary"><i class="fa fa-check"></i><b>4.6</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="optimal-individualized-treatment-regimes.html"><a href="optimal-individualized-treatment-regimes.html"><i class="fa fa-check"></i><b>5</b> Optimal Individualized Treatment Regimes</a><ul>
<li class="chapter" data-level="5.1" data-path="optimal-individualized-treatment-regimes.html"><a href="optimal-individualized-treatment-regimes.html#learning-objectives-3"><i class="fa fa-check"></i><b>5.1</b> Learning Objectives</a></li>
<li class="chapter" data-level="5.2" data-path="optimal-individualized-treatment-regimes.html"><a href="optimal-individualized-treatment-regimes.html#introduction-to-optimal-individualized-interventions"><i class="fa fa-check"></i><b>5.2</b> Introduction to Optimal Individualized Interventions</a></li>
<li class="chapter" data-level="5.3" data-path="optimal-individualized-treatment-regimes.html"><a href="optimal-individualized-treatment-regimes.html#data-structure-and-notation"><i class="fa fa-check"></i><b>5.3</b> Data Structure and Notation</a></li>
<li class="chapter" data-level="5.4" data-path="optimal-individualized-treatment-regimes.html"><a href="optimal-individualized-treatment-regimes.html#defining-the-causal-effect-of-an-optimal-individualized-intervention"><i class="fa fa-check"></i><b>5.4</b> Defining the Causal Effect of an Optimal Individualized Intervention</a><ul>
<li class="chapter" data-level="5.4.1" data-path="optimal-individualized-treatment-regimes.html"><a href="optimal-individualized-treatment-regimes.html#why-cv-tmle"><i class="fa fa-check"></i><b>5.4.1</b> Why CV-TMLE?</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="optimal-individualized-treatment-regimes.html"><a href="optimal-individualized-treatment-regimes.html#binary-treatment"><i class="fa fa-check"></i><b>5.5</b> Binary Treatment</a><ul>
<li class="chapter" data-level="5.5.1" data-path="optimal-individualized-treatment-regimes.html"><a href="optimal-individualized-treatment-regimes.html#evaluating-the-causal-effect-of-an-optimal-itr-with-binary-treatment"><i class="fa fa-check"></i><b>5.5.1</b> Evaluating the Causal Effect of an optimal ITR with Binary Treatment</a></li>
</ul></li>
<li class="chapter" data-level="5.6" data-path="optimal-individualized-treatment-regimes.html"><a href="optimal-individualized-treatment-regimes.html#categorical-treatment"><i class="fa fa-check"></i><b>5.6</b> Categorical Treatment</a><ul>
<li class="chapter" data-level="5.6.1" data-path="optimal-individualized-treatment-regimes.html"><a href="optimal-individualized-treatment-regimes.html#evaluating-the-causal-effect-of-an-optimal-itr-with-categorical-treatment"><i class="fa fa-check"></i><b>5.6.1</b> Evaluating the Causal Effect of an optimal ITR with Categorical Treatment</a></li>
</ul></li>
<li class="chapter" data-level="5.7" data-path="optimal-individualized-treatment-regimes.html"><a href="optimal-individualized-treatment-regimes.html#extensions-to-causal-effect-of-an-oit"><i class="fa fa-check"></i><b>5.7</b> Extensions to Causal Effect of an OIT</a><ul>
<li class="chapter" data-level="5.7.1" data-path="optimal-individualized-treatment-regimes.html"><a href="optimal-individualized-treatment-regimes.html#simpler-rules"><i class="fa fa-check"></i><b>5.7.1</b> Simpler Rules</a></li>
<li class="chapter" data-level="5.7.2" data-path="optimal-individualized-treatment-regimes.html"><a href="optimal-individualized-treatment-regimes.html#realistic-optimal-individual-regimes"><i class="fa fa-check"></i><b>5.7.2</b> Realistic Optimal Individual Regimes</a></li>
<li class="chapter" data-level="5.7.3" data-path="optimal-individualized-treatment-regimes.html"><a href="optimal-individualized-treatment-regimes.html#variable-importance-analysis"><i class="fa fa-check"></i><b>5.7.3</b> Variable Importance Analysis</a></li>
</ul></li>
<li class="chapter" data-level="5.8" data-path="optimal-individualized-treatment-regimes.html"><a href="optimal-individualized-treatment-regimes.html#exercise-2"><i class="fa fa-check"></i><b>5.8</b> Exercise</a><ul>
<li class="chapter" data-level="5.8.1" data-path="optimal-individualized-treatment-regimes.html"><a href="optimal-individualized-treatment-regimes.html#real-world-data-and-tmle3mopttx"><i class="fa fa-check"></i><b>5.8.1</b> Real World Data and <code>tmle3mopttx</code></a></li>
</ul></li>
<li class="chapter" data-level="5.9" data-path="optimal-individualized-treatment-regimes.html"><a href="optimal-individualized-treatment-regimes.html#summary-1"><i class="fa fa-check"></i><b>5.9</b> Summary</a><ul>
<li class="chapter" data-level="5.9.1" data-path="optimal-individualized-treatment-regimes.html"><a href="optimal-individualized-treatment-regimes.html#solutions"><i class="fa fa-check"></i><b>5.9.1</b> Solutions</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="stochastic-treatment-regimes.html"><a href="stochastic-treatment-regimes.html"><i class="fa fa-check"></i><b>6</b> Stochastic Treatment Regimes</a><ul>
<li class="chapter" data-level="6.1" data-path="stochastic-treatment-regimes.html"><a href="stochastic-treatment-regimes.html#learning-objectives-4"><i class="fa fa-check"></i><b>6.1</b> Learning Objectives</a></li>
<li class="chapter" data-level="6.2" data-path="stochastic-treatment-regimes.html"><a href="stochastic-treatment-regimes.html#introduction-1"><i class="fa fa-check"></i><b>6.2</b> Introduction</a></li>
<li class="chapter" data-level="6.3" data-path="stochastic-treatment-regimes.html"><a href="stochastic-treatment-regimes.html#stochastic-interventions"><i class="fa fa-check"></i><b>6.3</b> Stochastic Interventions</a><ul>
<li class="chapter" data-level="6.3.1" data-path="stochastic-treatment-regimes.html"><a href="stochastic-treatment-regimes.html#identifying-the-causal-effect-of-a-stochastic-intervention"><i class="fa fa-check"></i><b>6.3.1</b> Identifying the Causal Effect of a Stochastic Intervention</a></li>
<li class="chapter" data-level="6.3.2" data-path="stochastic-treatment-regimes.html"><a href="stochastic-treatment-regimes.html#interpreting-the-causal-effect-of-a-stochastic-intervention"><i class="fa fa-check"></i><b>6.3.2</b> Interpreting the Causal Effect of a Stochastic Intervention</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="stochastic-treatment-regimes.html"><a href="stochastic-treatment-regimes.html#estimating-the-causal-effect-of-a-stochastic-intervention-with-tmle3shift"><i class="fa fa-check"></i><b>6.4</b> Estimating the Causal Effect of a Stochastic Intervention with <code>tmle3shift</code></a><ul>
<li class="chapter" data-level="6.4.1" data-path="stochastic-treatment-regimes.html"><a href="stochastic-treatment-regimes.html#simulate-data-1"><i class="fa fa-check"></i><b>6.4.1</b> Simulate Data</a></li>
<li class="chapter" data-level="6.4.2" data-path="stochastic-treatment-regimes.html"><a href="stochastic-treatment-regimes.html#targeted-estimation-of-stochastic-interventions-effects"><i class="fa fa-check"></i><b>6.4.2</b> Targeted Estimation of Stochastic Interventions Effects</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="stochastic-treatment-regimes.html"><a href="stochastic-treatment-regimes.html#stochastic-interventions-over-a-grid-of-counterfactual-shifts"><i class="fa fa-check"></i><b>6.5</b> Stochastic Interventions over a Grid of Counterfactual Shifts</a><ul>
<li class="chapter" data-level="6.5.1" data-path="stochastic-treatment-regimes.html"><a href="stochastic-treatment-regimes.html#initializing-vimshift-through-its-tmle3_spec"><i class="fa fa-check"></i><b>6.5.1</b> Initializing <code>vimshift</code> through its <code>tmle3_Spec</code></a></li>
<li class="chapter" data-level="6.5.2" data-path="stochastic-treatment-regimes.html"><a href="stochastic-treatment-regimes.html#targeted-estimation-of-stochastic-intervention-effects"><i class="fa fa-check"></i><b>6.5.2</b> Targeted Estimation of Stochastic Intervention Effects</a></li>
<li class="chapter" data-level="6.5.3" data-path="stochastic-treatment-regimes.html"><a href="stochastic-treatment-regimes.html#inference-with-marginal-structural-models"><i class="fa fa-check"></i><b>6.5.3</b> Inference with Marginal Structural Models</a></li>
<li class="chapter" data-level="6.5.4" data-path="stochastic-treatment-regimes.html"><a href="stochastic-treatment-regimes.html#directly-targeting-the-msm-parameter-beta"><i class="fa fa-check"></i><b>6.5.4</b> Directly Targeting the MSM Parameter <span class="math inline">\(\beta\)</span></a></li>
<li class="chapter" data-level="6.5.5" data-path="stochastic-treatment-regimes.html"><a href="stochastic-treatment-regimes.html#example-with-the-wash-benefits-data"><i class="fa fa-check"></i><b>6.5.5</b> Example with the WASH Benefits Data</a></li>
</ul></li>
<li class="chapter" data-level="6.6" data-path="stochastic-treatment-regimes.html"><a href="stochastic-treatment-regimes.html#exercises"><i class="fa fa-check"></i><b>6.6</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="r6.html"><a href="r6.html"><i class="fa fa-check"></i><b>7</b> A Primer on the <code>R6</code> Class System</a><ul>
<li class="chapter" data-level="7.1" data-path="r6.html"><a href="r6.html#classes-fields-and-methods"><i class="fa fa-check"></i><b>7.1</b> Classes, Fields, and Methods</a></li>
<li class="chapter" data-level="7.2" data-path="r6.html"><a href="r6.html#object-oriented-programming-python-and-r"><i class="fa fa-check"></i><b>7.2</b> Object Oriented Programming: <code>Python</code> and <code>R</code></a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">The <code>tlverse</code> Software Ecosystem for Causal Inference</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="intro" class="section level1">
<h1><span class="header-section-number">Chapter 1</span> The Targeted Learning Roadmap</h1>
<p>A central goal of the Targeted Learning statistical paradigm is to estimate
scientifically relevant parameters in realistic (usually nonparametric) models.</p>
<div id="the-statistical-model" class="section level2">
<h2><span class="header-section-number">1.1</span> The Statistical Model</h2>
<p>Assume we have an i.i.d. sample of confounders, a binary intervention of
interest, and an outcome, or are observed data is <span class="math inline">\(O = (W, A, Y)\)</span>. The
distribution of the observed data may be factorized as follows: <span class="math inline">\(P(O) = P(W, A, Y) = P(W)P (A \mid W) P(Y \mid A, W)\)</span>. To estimate a parameter of interest, a
researcher need not necessarily be able to specify these whole or conditional
distributions. Rather, each estimator only requires that certain parts of the
distribution be known; for example, some may require estimates of <span class="math inline">\(\mathbb{E}(Y \mid A, W)\)</span>, the mean of <span class="math inline">\(Y\)</span> within subgroups <span class="math inline">\((A, W)\)</span>, or the regression of the
outcome on the exposure and confounders.</p>
<p>At this stage in the roadmap, the researcher must specify a choice of
statistical model to be used in estimating <span class="math inline">\(\mathbb{E}(Y \mid A, W)\)</span> or other
elements of the probability distribution needed to estimate the parameter of
interest. Here, <em>statistical model</em> means any constraints on the model form that
may be imposed by knowledge about the data-generating process – that is, known
aspects of how the data were generated. Typically, the <em>true model</em> is a very
large model, placing few constraints, if any, on the data-generating
distribution, or a semi-parametric model. With few constraints on the
data-generating distribution, and a potentially large number of covariates,
data-adaptive, machine-learning approaches remain the only practical option for
estimating components of the likelihood. The remainder of this course concerns
how to do this as efficiently and robustly as possible, depending on the goal of
the analysis.</p>
</div>
<div id="the-causal-model" class="section level2">
<h2><span class="header-section-number">1.2</span> The Causal Model</h2>
<p>The next step in the roadmap is to use a causal framework to formalize the
experiment and thereby define the parameter of interest. Causal graphs are one
useful tool to express what we know about the causal relations among variables
that are relevant to the question under study <span class="citation">(Pearl <a href="#ref-pearl2009causality">2009</a>)</span>.</p>
<p>Ignoring error terms, we will assume the following ordering of the variables in <span class="math inline">\(O\)</span>.</p>
<div id="htmlwidget-6a40192e6cb193498f75" style="width:200px;height:300px;" class="visNetwork html-widget"></div>
<script type="application/json" data-for="htmlwidget-6a40192e6cb193498f75">{"x":{"nodes":{"id":["W","A","Y"],"label":["W","A","Y"]},"edges":{"from":["W","W","A"],"to":["A","Y","Y"]},"nodesToDataframe":true,"edgesToDataframe":true,"options":{"width":"100%","height":"100%","nodes":{"shape":"dot"},"manipulation":{"enabled":false},"edges":{"arrows":{"to":true}},"layout":{"randomSeed":25}},"groups":null,"width":"200px","height":"300px","idselection":{"enabled":false},"byselection":{"enabled":false},"main":null,"submain":null,"footer":null,"background":"rgba(0, 0, 0, 0)"},"evals":[],"jsHooks":[]}</script>
<p>While
directed acyclic graphs (DAGs - like above) provide a convenient means by which to visualize
causal relations between variables, the causal relations among variables
can be represented via a set of structural equations:
<span class="math display">\[\begin{align*}
  W &amp;= f_W(U_W) \\
  A &amp;= f_A(W, U_A) \\
  Y &amp;= f_Y(W, A, U_Y),
\end{align*}\]</span>
where <span class="math inline">\(U_W\)</span>, <span class="math inline">\(U_A\)</span>, and <span class="math inline">\(U_Y\)</span> represent the unmeasured exogenous background
characteristics that influence the value of each variable. In the NPSEM, <span class="math inline">\(f_W\)</span>,
<span class="math inline">\(f_A\)</span> and <span class="math inline">\(f_Y\)</span> denote that each variable (for <span class="math inline">\(W\)</span>, <span class="math inline">\(A\)</span> and <span class="math inline">\(Y\)</span>, respectively)
is a function of its parents and unmeasured background characteristics, but one
typically has little information about particular functional constraints (e.g.,
linear, logit-linear, only one interaction, etc.). For this reason, they are
called non-parametric structural equation models (NPSEMs). The DAG and set of
nonparametric structural equations represent exactly the same information and so
may be used interchangeably.</p>
</div>
<div id="the-parameter-of-interest" class="section level2">
<h2><span class="header-section-number">1.3</span> The Parameter of Interest</h2>
<p>The first hypothetical experiment we will consider is assigning exposure to the
whole population and observing the outcome, and then assigning no exposure to
the whole population and observing the outcome. On the nonparametric structural
equations, this corresponds to a comparison of the outcome distribution in the
population under two interventions:</p>
<ol style="list-style-type: decimal">
<li><span class="math inline">\(A\)</span> is set to <span class="math inline">\(1\)</span> for all individuals, and</li>
<li><span class="math inline">\(A\)</span> is set to <span class="math inline">\(0\)</span> for all individuals.</li>
</ol>
<p>These interventions imply two new nonparametric structural equation models. For
the case <span class="math inline">\(A = 1\)</span>, we have
<span class="math display">\[\begin{align*}
  W &amp;= f_W(U_W) \\
  A &amp;= 1 \\
  Y(1) &amp;= f_Y(W, 1, U_Y),
\end{align*}\]</span>
and for the case <span class="math inline">\(A=0\)</span>,
<span class="math display">\[\begin{align*}
  W &amp;= f_W(U_W) \\
  A &amp;= 0 \\
  Y(1) &amp;= f_Y(W, 0, U_Y).
\end{align*}\]</span></p>
<p>In these equations, <span class="math inline">\(A\)</span> is no longer a function of <span class="math inline">\(W\)</span> because we have
intervened on the system, setting <span class="math inline">\(A\)</span> deterministically to either of the values
<span class="math inline">\(1\)</span> or <span class="math inline">\(0\)</span>. The new symbols <span class="math inline">\(Y(1)\)</span> and <span class="math inline">\(Y(0)\)</span> indicate the outcome variable in
our population if it were generated by the respective NPSEMs above; these are
often called <em>counterfactuals</em>. The difference between the means of the outcome
under these two interventions defines a parameter that is often called the
“average treatment effect” (ATE), denoted
<span class="math display">\[\begin{equation}\label{eqn:ate}
  ATE = \mathbb{E}_X(Y(1)-Y(0)),
\end{equation}\]</span>
where <span class="math inline">\(\mathbb{E}_X\)</span> is the mean under the theoretical (unobserved) full data
<span class="math inline">\(X = (W, Y(1), Y(0))\)</span>.</p>
</div>
<div id="identifiability" class="section level2">
<h2><span class="header-section-number">1.4</span> Identifiability</h2>
<p>Because we can never observe both <span class="math inline">\(Y(0)\)</span> (the counterfactual outcome when <span class="math inline">\(A=0\)</span>)
and <span class="math inline">\(Y(1)\)</span>, we cannot estimate  directly. Instead, we have to make
assumptions under which this quantity may be estimated from the observed data
<span class="math inline">\(O \sim P_0\)</span> under the data-generating distribution <span class="math inline">\(P_0\)</span>. Fortunately, given
the causal model specified in the NPSEM above, we can, with a handful of
untestable assumptions, estimate the ATE, even from observational data. These
assumptions may be summarized as follows</p>
<ol style="list-style-type: decimal">
<li>The causal graph implies <span class="math inline">\(Y(a) \perp A\)</span> for all <span class="math inline">\(a \in \mathcal{A}\)</span>, which
is the <em>randomization</em> assumption. In the case of observational data, the
analogous assumption is <em>strong ignorability</em> or <em>no unmeasured confounding</em>
<span class="math inline">\(Y(a) \perp A \mid W\)</span> for all <span class="math inline">\(a \in \mathcal{A}\)</span>;</li>
<li>Although not represented in the causal graph, also required is the assumption
of no interference between units, that is, the outcome for unit <span class="math inline">\(i\)</span> <span class="math inline">\(Y_i\)</span> is
not affected by exposure for unit <span class="math inline">\(j\)</span> <span class="math inline">\(A_j\)</span> unless <span class="math inline">\(i=j\)</span>;</li>
<li><em>Consistency</em> of the treatment mechanism is also required, i.e., the outcome
for unit <span class="math inline">\(i\)</span> is <span class="math inline">\(Y_i(a)\)</span> whenever <span class="math inline">\(A_i = a\)</span>, an assumption also known as “no
other versions of treatment”;</li>
<li>It is also necessary that all observed units, across strata defined by <span class="math inline">\(W\)</span>,
have a bounded (non-deterministic) probability of receiving treatment –
that is, <span class="math inline">\(0 &lt; P_0(A = a \mid W) &lt; 1\)</span> for all <span class="math inline">\(a\)</span> and <span class="math inline">\(W\)</span>). This assumption is
referred to as <em>positivity</em>.</li>
</ol>
<p><em>Remark</em>: Together, (2) and (3), the assumptions of no interference and
consistency, respectively, are jointly referred to as the <em>stable unit
treatment value assumption</em> (SUTVA).</p>
<p>Given these assumptions, the ATE may be re-written as a function of <span class="math inline">\(P_0\)</span>,
specifically
<span class="math display">\[\begin{equation}\label{eqn:estimand}
  ATE = \mathbb{E}_0(Y(1) - Y(0)) = \mathbb{E}_0
    \left(\mathbb{E}_0[Y \mid A = 1, W] - \mathbb{E}_0[Y \mid A = 0, W]\right),
\end{equation}\]</span>
or the difference in the predicted outcome values for each subject, under the
contrast of treatment conditions (<span class="math inline">\(A = 0\)</span> vs. <span class="math inline">\(A = 1\)</span>), in the population,
averaged over all observations. Thus, a parameter of a theoretical “full” data
distribution can be represented as an estimand of the observed data
distribution. Significantly, there is nothing about the representation in
 that requires parameteric assumptions; thus, the regressions
on the right hand side may be estimated freely with machine learning. With
different parameters, there will be potentially different identifiability
assumptions and the resulting estimands can be functions of different components
of <span class="math inline">\(P_0\)</span>. We discuss several more complex estimands in later sections of this
workshop.</p>
</div>
<div id="estimators-superlearning-and-targeted-maximum-likelihood" class="section level2">
<h2><span class="header-section-number">1.5</span> Estimators: SuperLearning and Targeted Maximum Likelihood</h2>
<p>Although we will discuss more in later sections, the goals of the estimators we
desire should be that, among sensible (asymptotically consistent, regular)
estimators,</p>
<ol style="list-style-type: decimal">
<li>the estimator be asymptotically efficient in the statistical model of
interest, and</li>
<li>the estimator can be constructed for finite-sample performance improvements,
relative to other estimators in the same class.</li>
</ol>
<p>These priniciples guide our approach to estimation: Super Learning for
prediction (more generally density estimation) and TMLE for estimation of our
intervention parameters of interest.</p>
<pre class="sourceCode r"><code class="sourceCode r">knitr<span class="op">::</span><span class="kw">include_graphics</span>(<span class="st">&quot;img/misc/NatureSlides.pdf&quot;</span>)</code></pre>
<embed src="img/misc/NatureSlides.pdf" width="  extwidth" style="display: block; margin: auto;" type="application/pdf" />
<div id="superlearning" class="section level3">
<h3><span class="header-section-number">1.5.1</span> SuperLearning</h3>
<ul>
<li>There is no universally optimal machine learning algorithm (exceptions exist
– HAL).</li>
<li>This is true empirically, when we have test different algorithms on actual
data and looked at the performance (e.g., MSE of prediction)</li>
<li>For some data, one needs learners that can model a complex function.</li>
<li>For others, typically caused by noise or insufficient sample size, a simple,
parametric model might fit the best.</li>
<li>SuperLearner, an ensemble learner, solves this issue, by allowing a convex
combination of learners from the simplest (intercept-only) to most complex
(neural nets, random forests, SVM, etc).</li>
<li>It works by using cross-validation in a manner which guarantees that the
resulting fit will be as good as possible, given the learners provided (note,
even a convex combination of poor learners can sometimes result in good fit,
though better to have good candidates).</li>
</ul>
<pre class="sourceCode r"><code class="sourceCode r">knitr<span class="op">::</span><span class="kw">include_graphics</span>(<span class="st">&quot;img/misc/vs.pdf&quot;</span>)</code></pre>
<embed src="img/misc/vs.pdf" width="    extwidth" style="display: block; margin: auto;" type="application/pdf" />
<p>The figure above shows an example of 10-fold cross-validation.</p>
<p>Below, we show both an example of how even non-optimal learners can fit complex
functions within Super Learner as well as results of an empirical study of
Super Learner versus other learners across many data sets.</p>
</div>
<div id="tmle" class="section level3">
<h3><span class="header-section-number">1.5.2</span> TMLE</h3>
<ul>
<li>Augmentation of substitution estimators
<ul>
<li>Defines a mapping from the true distribution to a parameter(s), <span class="math inline">\(\Psi(P_0)\)</span></li>
<li>A substitution estimator uses the same mapping, but plug-in estimates of the
relevant parts of distirbution <span class="math inline">\(\Psi(P_n)\)</span>.</li>
<li>TMLE does a targed augmentation of the estimate of the relevant parts of the
distribution, but uses same mapping <span class="math inline">\(\Psi(P^*_n)\)</span>.</li>
</ul></li>
<li>Produces a well-defined, unbiased, efficient substitution estimator of target
parameters of a data-generating distribution.</li>
<li>Updates an initial (super learner) estimate of the relevant part of the
data-generating distribution possibly using an estimate of a nuisance
parameter (like the model of intervention given covariates).</li>
<li>Removes asymptotic residual bias of initial estimator for the target
parameter, if it uses a consistent estimator of <span class="math inline">\(g_0\)</span>.</li>
<li>If initial estimator was consistent for the target parameter, the additional
fitting of the data in the targeting step may remove finite sample bias, and
preserves consistency property of the initial estimator.</li>
<li>If the initial estimator and the estimator of <span class="math inline">\(g_0\)</span> are both consistent, then
it is also asymptotically efficient according to semi-parametric statistical
model efficiency theory.</li>
<li>Thus, every effort is made to achieve minimal bias and the asymptotic
semi-parametric efficiency bound for the variance.</li>
</ul>
<!--

```r
knitr::include_graphics("img/misc/NatureSlides_3.pdf")
```

<embed src="img/misc/NatureSlides_3.pdf" width="    extwidth" style="display: block; margin: auto;" type="application/pdf" />

```r
knitr::include_graphics("img/misc/NatureSlides_4.pdf")
```

<embed src="img/misc/NatureSlides_4.pdf" width="    extwidth" style="display: block; margin: auto;" type="application/pdf" />

```r
knitr::include_graphics("img/misc/NatureSlides_5.pdf")
```

<embed src="img/misc/NatureSlides_5.pdf" width="    extwidth" style="display: block; margin: auto;" type="application/pdf" />
-->
<p>]</p>
<p>]</p>
<p>]</p>
</div>
<div id="inference" class="section level3">
<h3><span class="header-section-number">1.5.3</span> Inference</h3>
<p>The estimators we discuss are asymptotically linear, meaning that the difference
in the estimate <span class="math inline">\(\Psi(P_n)\)</span> and the true parameter (<span class="math inline">\(\Psi(P_0)\)</span>) can be
represented in first order by a i.i.d. sum:
<span class="math display">\[\begin{equation}\label{eqn:IC}
  \Psi(P_n) - \Psi(P_0) = \frac{1}{n} IC(O_i; \nu) + op(1/\sqrt{n})
\end{equation}\]</span>
where <span class="math inline">\(IC(O_i; \nu)\)</span> is a function of the data and possibly other parameters
<span class="math inline">\(\nu\)</span>. Importantly, such estimators have mean-zero Gaussian limiting
distributions; thus, in the univariate case, one has that
<span class="math display">\[\begin{equation}\label{eqn:limit_dist}
  \sqrt{n}(\Psi(P_n) - \Psi(P_0)) = N(0, (IC(O_i; \nu))^2),
\end{equation}\]</span>
so that inference for the estimator of interest may be obtained in terms of
the influence function. For this simple case, a 95% confidence interval may be
derived as:
<span class="math display">\[\begin{equation}\label{eqn:CI}
  \Psi(P^{\star}_n) \pm 1.96 \sqrt{\frac{\hat{\sigma}^2}{n}},
\end{equation}\]</span>
where <span class="math inline">\(SE=\sqrt{\frac{\hat{\sigma}^2}{n}}\)</span> and <span class="math inline">\(\hat{\sigma}^2\)</span> is the sample
variance of the estimated IC’s: <span class="math inline">\(IC(O; \hat{\nu})\)</span>. One can use the functional
delta method to derive the influence curve if a parameter of interest may be
written as a function of other asymptotically linear estimators.</p>
</div>
</div>
<div id="the-wash-benefits-example-dataset" class="section level2">
<h2><span class="header-section-number">1.6</span> The WASH Benefits Example Dataset</h2>
<p>The data come from a study of the effect of water quality, sanitation, hand
washing, and nutritional interventions on child development in rural Bangladesh
(WASH Benefits Bangladesh): a cluster-randomised controlled trial
<span class="citation">(“Temporary,” <a href="#ref-luby2018effects">n.d.</a>)</span>. The study enrolled pregnant women in their first or second
trimester from the rural villages of Gazipur, Kishoreganj, Mymensingh, and
Tangail districts of central Bangladesh, with an average of eight women per
cluster. Groups of eight geographically adjacent clusters were block-randomised,
using a random number generator, into six intervention groups (all of which
received weekly visits from a community health promoter for the first 6 months
and every 2 weeks for the next 18 months) and a double-sized control group (no
intervention or health promoter visit). The six intervention groups were:</p>
<ol style="list-style-type: decimal">
<li>chlorinated drinking water;</li>
<li>improved sanitation;</li>
<li>handwashing with soap;</li>
<li>combined water, sanitation, and hand washing;</li>
<li>improved nutrition through counseling and provision of lipid-based nutrient
supplements; and</li>
<li>combined water, sanitation, handwashing, and nutrition.</li>
</ol>
<p>In the workshop, we concentrate on child growth (size for age) as the outcome of
interest. For referene, this trial was registered with ClinicalTrials.gov as
NCT01590095.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(here)
<span class="kw">library</span>(tidyverse)

<span class="co"># read in data</span>
dat &lt;-<span class="st"> </span><span class="kw">read_csv</span>(<span class="kw">here</span>(<span class="st">&quot;data&quot;</span>, <span class="st">&quot;washb_data.csv&quot;</span>))
dat</code></pre>
<pre><code># A tibble: 4,695 x 28
     whz tr    fracode month  aged sex   momage momedu momheight hfiacat Nlt18
   &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;  &lt;dbl&gt; &lt;chr&gt;      &lt;dbl&gt; &lt;chr&gt;   &lt;dbl&gt;
 1  0    Cont… N05265      9   268 male      30 Prima…      146. Food S…     3
 2 -1.16 Cont… N05265      9   286 male      25 Prima…      149. Modera…     2
 3 -1.05 Cont… N08002      9   264 male      25 Prima…      152. Food S…     1
 4 -1.26 Cont… N08002      9   252 fema…     28 Prima…      140. Food S…     3
 5 -0.59 Cont… N06531      9   336 fema…     19 Secon…      151. Food S…     2
 6 -0.51 Cont… N06531      9   304 male      20 Secon…      154. Severe…     0
 7 -2.46 Cont… N08002      9   336 fema…     19 Prima…      151. Food S…     2
 8 -0.6  Cont… N06528      9   312 fema…     25 No ed…      142. Food S…     2
 9 -0.23 Cont… N06528      9   322 male      30 Secon…      153. Food S…     1
10 -0.14 Cont… N06453      9   376 male      30 No ed…      156. Modera…     2
# … with 4,685 more rows, and 17 more variables: Ncomp &lt;dbl&gt;, watmin &lt;dbl&gt;,
#   elec &lt;dbl&gt;, floor &lt;dbl&gt;, walls &lt;dbl&gt;, roof &lt;dbl&gt;, asset_wardrobe &lt;dbl&gt;,
#   asset_table &lt;dbl&gt;, asset_chair &lt;dbl&gt;, asset_khat &lt;dbl&gt;, asset_chouki &lt;dbl&gt;,
#   asset_tv &lt;dbl&gt;, asset_refrig &lt;dbl&gt;, asset_bike &lt;dbl&gt;, asset_moto &lt;dbl&gt;,
#   asset_sewmach &lt;dbl&gt;, asset_mobile &lt;dbl&gt;</code></pre>
<p>For the purposes of this workshop, we we start by treating the data as
independent and identically distributed (i.i.d.) random draws from a very large
target population. We could, with available options, account for the clustering
of the data (within sampled geographic units), but, for simplification, we avoid
these details in these workshop presentations, although modifications of our
methodology for biased samples, repeated measures, etc., are available.</p>
<p>We have 28 variables measured, of which 1 variable is set to be the outcome of
interest. This outcome, <span class="math inline">\(Y\)</span>, is the weight-for-height Z-score (<code>whz</code> in <code>dat</code>);
the treatment of interest, <span class="math inline">\(A\)</span>, is the randomized treatment group (<code>tr</code> in
<code>dat</code>); and the adjustment set, <span class="math inline">\(W\)</span>, consists simply of <em>everything else</em>. This
results in our observed data structure being <span class="math inline">\(n\)</span> i.i.d. copies of <span class="math inline">\(O_i = (W_i, A_i, Y_i)\)</span>, for <span class="math inline">\(i = 1, \ldots, n\)</span>.</p>
<div id="the-variables" class="section level3">
<h3><span class="header-section-number">1.6.1</span> The variables</h3>
<p>Using the <a href="https://CRAN.R-project.org/package=skimr"><code>skimr</code> package</a>, we can
quickly summarize the variables measured in the WASH Benefits data set:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(skimr)
<span class="kw">skim</span>(dat)</code></pre>
<pre><code>Skim summary statistics
 n obs: 4695 
 n variables: 28 

── Variable type:character ─────────────────────────────────────────────────────
 variable missing complete    n min max empty n_unique
  fracode       0     4695 4695   2   6     0       20
  hfiacat       0     4695 4695  11  24     0        4
   momedu       0     4695 4695  12  15     0        3
      sex       0     4695 4695   4   6     0        2
       tr       0     4695 4695   3  15     0        7

── Variable type:numeric ───────────────────────────────────────────────────────
       variable missing complete    n    mean    sd     p0    p25   p50    p75
           aged       0     4695 4695 266.32  52.17  42    230    266   303   
     asset_bike       0     4695 4695   0.32   0.47   0      0      0     1   
    asset_chair       0     4695 4695   0.73   0.44   0      0      1     1   
   asset_chouki       0     4695 4695   0.78   0.41   0      1      1     1   
     asset_khat       0     4695 4695   0.61   0.49   0      0      1     1   
   asset_mobile       0     4695 4695   0.86   0.35   0      1      1     1   
     asset_moto       0     4695 4695   0.066  0.25   0      0      0     0   
   asset_refrig       0     4695 4695   0.079  0.27   0      0      0     0   
  asset_sewmach       0     4695 4695   0.065  0.25   0      0      0     0   
    asset_table       0     4695 4695   0.73   0.44   0      0      1     1   
       asset_tv       0     4695 4695   0.3    0.46   0      0      0     1   
 asset_wardrobe       0     4695 4695   0.17   0.37   0      0      0     0   
           elec       0     4695 4695   0.6    0.49   0      0      1     1   
          floor       0     4695 4695   0.11   0.31   0      0      0     0   
         momage      18     4677 4695  23.91   5.24  14     20     23    27   
      momheight      31     4664 4695 150.5    5.23 120.65 147.05 150.6 154.06
          month       0     4695 4695   6.45   3.33   1      4      6     9   
          Ncomp       0     4695 4695  11.04   6.35   2      6     10    14   
          Nlt18       0     4695 4695   1.6    1.25   0      1      1     2   
           roof       0     4695 4695   0.99   0.12   0      1      1     1   
          walls       0     4695 4695   0.72   0.45   0      0      1     1   
         watmin       0     4695 4695   0.95   9.48   0      0      0     1   
            whz       0     4695 4695  -0.59   1.03  -4.67  -1.28  -0.6   0.08
   p100     hist
 460    ▁▁▂▇▇▅▁▁
   1    ▇▁▁▁▁▁▁▃
   1    ▃▁▁▁▁▁▁▇
   1    ▂▁▁▁▁▁▁▇
   1    ▅▁▁▁▁▁▁▇
   1    ▁▁▁▁▁▁▁▇
   1    ▇▁▁▁▁▁▁▁
   1    ▇▁▁▁▁▁▁▁
   1    ▇▁▁▁▁▁▁▁
   1    ▃▁▁▁▁▁▁▇
   1    ▇▁▁▁▁▁▁▃
   1    ▇▁▁▁▁▁▁▂
   1    ▆▁▁▁▁▁▁▇
   1    ▇▁▁▁▁▁▁▁
  60    ▅▇▅▂▁▁▁▁
 168    ▁▁▁▂▇▇▂▁
  12    ▅▃▇▃▂▇▃▅
  52    ▇▇▃▁▁▁▁▁
  10    ▇▃▂▁▁▁▁▁
   1    ▁▁▁▁▁▁▁▇
   1    ▃▁▁▁▁▁▁▇
 600    ▇▁▁▁▁▁▁▁
   4.97 ▁▁▅▇▃▁▁▁</code></pre>
<p>A convenient summary of the relevant variables is given just above, complete
with a small visualization describing the marginal characteristics of each
covariate. Note that the <em>asset</em> variables reflect socio-economic status of the
study participants. Notice also the uniform distribution of the treatment groups
(with twice as many controls); this is, of course, by design.</p>

</div>
</div>
</div>
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-pearl2009causality">
<p>Pearl, Judea. 2009. <em>Causality: Models, Reasoning, and Inference</em>. Cambridge University Press.</p>
</div>
<div id="ref-luby2018effects">
<p>“Temporary.” n.d.</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="motivation.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="tlverse.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": false,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/tlverse/acic2019-workshop/edit/master/02-intro.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"download": ["acic2019_workshop.pdf", "acic2019_workshop.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
